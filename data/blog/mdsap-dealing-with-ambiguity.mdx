---
title: How many MDSAP tasks would it take to screw in a lightbulb?
date: '2022-11-15'
tags: ['qms-philosophy']
summary: Acknowledging and rolling with MDSAP ambiguity.
slug: mdsap-dealing-with-ambiguity
---

How many MDSAP tasks would it take to screw in a lightbulb? 

I'll give you a hint.  The answer is between 1 and 12.  The answer is surely ambiguous, unverifiable, and in conflict with itself. This stems from a major flaw of MDSAP, which I think of as 'task abstraction level'. Some tasks are at very high level while others are at very low level. 

But this is just one flaw among several.  Let's visit each other them.

## Task abstraction level 

Some tasks, like 3-12 Evaluation of Information from Post-production Phase, Including Complaints of 5-8 Risk Management Activities Applied throughout the Design and Development Project have relatively massive scopes from a QMS process perspective.

Compare this to other parts of the audit model where a relatively trivial and/or small aspect of a QMS process is elevated to task status, such as the splitting of hairs between 5-6 Design and Development Input and 5-7 Completeness, Coherence, and Unambiguity of Design and Development Input. 

As if we were going to do a thorough audit of design inputs in 5-6 but put some blinders on to the completeness of those audited design inputs until 5-7. 

## Sequence and ordering of tasks
Have you and your team been confused by the sequence of the  MDSAP audit model?

A fundamental premise of MDSAP is that sequence matters, and that the audit sequence *should* be followed as designed.

But the sequence definitely isn't perfect and if followed exactly, is sometimes awkward and inefficient.  If you've ever tried to follow it and it didn't make sense to you, just know it's not *you*, it's the (broken) audit model.

And this brings us to the second categorical flaw of MDSAP - the sequence of the established tasks.

To name just a few that used to throw me. (We'll not yet name the nonsequential-redundant tasks, more on redundancy later).

- Task 1-10 Distribution of Devices with Appropriate Marketing Authorization is awkwardly placed in the management process. There are better homes for this as there is clearly a stronger link to production controls, such as Review of Customer Requirements & Distribution (Task 6-25).   
- 3-10 Internal Audit should be the first or second task in Chapter 3.  It is relevant to know what has been sampled in previous audits, and where problems have been identified.
- 5-12 Software Design and Development is awkwardly placed after design validation and clinical evaluation.  If an auditor only starts to consider software this late, they will not achieve 'efficiency' or make meaningful links! They will likely be running in circles in documents and topics already covered.  
- 5-8 Risk Management Activities Applied Throughout the Design and Development Project should arguably be just after 5-3 Design and Development Planning. Risk management is to itself have planning and inform both inputs and outputs, so why is its task after all three of these?
- Task 5-15 Impact Review of Design and Development Changes is discontinuous from Task 5-13 Design and Development Changes, and they should be one in the same.
- Task 6-16 Device Master File is awkwardly placed in the middle of Chapter 6, yet a DMF/DMR index is an incredibly useful document to guide all of Chapter 6, especially as early as Task 6-3 Controls for the implementation of Selected Production and Service Process(es). 
- 6-28 Risk Controls Applied to Transport, Installation is placed so very late and seems to be a subset from the overarching 6-3 Controls for the Implementation of Selected Production and Service Process(es).  Though if you didn't start your considerations for this in design outputs (5-7), design verification of risk controls (5-9), and design transfer (5-16) this will likely throw you for a loop. 

Don't even get me started on the placement of 'country-specific requirements!'

In the end, I think it is important for the audit model to lead by example, and be a really polished example of a 'process approach'.  Sequence matters, and the sequence should be really polished.

But were stuck with it for now, and you have some flexibility, so don't let a rigid sequence detract from your audit.  

And breathe easy knowing that the problem is not you, it's the audit model... 

I hear you though.  You're saying, who cares about this though, sequence flaws pale in comparison to the redundancy! Now what could we possibly say about *redundancy*?...

### Is sequencing actually important then?
I agree that sequencing of tasks is important.  Sequencing of tasks is in complete harmony with the idea of a 'process approach', recognizing that some QMS activities should be reviewed before others. 

An audit is also a process, and sampling of initial processes will influence sampling of later processes. 

For example, MDSAP rightfully puts Management Review very early on in the audit.  This makes sense as it is a dense summary of quality data, and it can inform the entire rest of the audit. Similarly, reviewing CAPA and nonconforming product regularly influences sampling of Design, Production, and Purchasing to a great degree.

For example a production related CAPA might completely influence the selection of products and processes to audit in Chapter 6.  
If you were following an ISO 13485 structure it may be too late to make links and perform meaningful sampling.

## Redundant tasks
In progress!
## Conclusion

On one hand I like the idea of an audit task model, but MDSAP needs a lot of improvement and you have to acknowledge some categorical flaws in order to perform a successful audit. 

I havn't seen any good practical resources on approaching MDSAP, so I've started to create my own after auditing to it for several years now. Looking forward to sharing more takeaways. 

I'm curious, what's most confusing to you about MDSAP?  What would help your MDSAP-based internal audit program be more effective? 
 
